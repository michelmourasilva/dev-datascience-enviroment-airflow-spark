[2022-02-19 00:32:33,930] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: spark-test-cassandra.create_table manual__2022-02-19T00:32:01.622436+00:00 [queued]>
[2022-02-19 00:32:33,943] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: spark-test-cassandra.create_table manual__2022-02-19T00:32:01.622436+00:00 [queued]>
[2022-02-19 00:32:33,943] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:32:33,943] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-19 00:32:33,943] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:32:33,955] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): create_table> on 2022-02-19 00:32:01.622436+00:00
[2022-02-19 00:32:33,959] {standard_task_runner.py:52} INFO - Started process 250 to run task
[2022-02-19 00:32:33,963] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'spark-test-cassandra', 'create_table', 'manual__2022-02-19T00:32:01.622436+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/spark-cassandra-dag.py', '--cfg-path', '/tmp/tmp5e0dmmad', '--error-file', '/tmp/tmpf0aydmq5']
[2022-02-19 00:32:33,963] {standard_task_runner.py:77} INFO - Job 5: Subtask create_table
[2022-02-19 00:32:34,011] {logging_mixin.py:109} INFO - Running <TaskInstance: spark-test-cassandra.create_table manual__2022-02-19T00:32:01.622436+00:00 [running]> on host 2e85b2b3b082
[2022-02-19 00:32:34,059] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Airflow
AIRFLOW_CTX_DAG_ID=spark-test-cassandra
AIRFLOW_CTX_TASK_ID=create_table
AIRFLOW_CTX_EXECUTION_DATE=2022-02-19T00:32:01.622436+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-02-19T00:32:01.622436+00:00
[2022-02-19 00:32:34,067] {base.py:79} INFO - Using connection to: id: ***_default. Host: 172.20.0.11, Port: 9042, Schema: None, Login: ***, Password: ***, extra: {}
[2022-02-19 00:32:34,068] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/apache/***/hooks/***.py:123: DeprecationWarning: Legacy execution parameters will be removed in 4.0. Consider using execution profiles.
  self.cluster = Cluster(**conn_config)

[2022-02-19 00:32:34,074] {cassandra.py:131} WARNING - Downgrading core protocol version from 66 to 65 for 172.20.0.11:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/***/cluster.html#***.cluster.Cluster.protocol_version
[2022-02-19 00:32:34,077] {cassandra.py:131} WARNING - Downgrading core protocol version from 65 to 5 for 172.20.0.11:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/***/cluster.html#***.cluster.Cluster.protocol_version
[2022-02-19 00:32:34,079] {libevreactor.py:370} ERROR - Closing connection <LibevConnection(140311503012240) 172.20.0.11:9042> due to protocol error: Error from server: code=000a [Protocol error] message="Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset"
[2022-02-19 00:32:34,079] {cassandra.py:131} WARNING - Downgrading core protocol version from 5 to 4 for 172.20.0.11:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/***/cluster.html#***.cluster.Cluster.protocol_version
[2022-02-19 00:32:34,652] {logging_mixin.py:109} INFO - >>>>>>>>>>> Executed: Keyspace and Tables are created
[2022-02-19 00:32:34,652] {python.py:175} INFO - Done. Returned value was: None
[2022-02-19 00:32:34,664] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=spark-test-***, task_id=create_table, execution_date=20220219T003201, start_date=20220219T003233, end_date=20220219T003234
[2022-02-19 00:32:34,696] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 00:32:34,736] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
