[2022-02-19 00:31:24,733] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 00:31:24,749] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 00:31:24,749] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:31:24,749] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-19 00:31:24,749] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:31:24,769] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): bash_task> on 2020-01-01 00:00:00+00:00
[2022-02-19 00:31:24,774] {standard_task_runner.py:52} INFO - Started process 171 to run task
[2022-02-19 00:31:24,777] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'configuration_dag', 'bash_task', 'scheduled__2020-01-01T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/configuration_dag.py', '--cfg-path', '/tmp/tmpi08llhjq', '--error-file', '/tmp/tmpzlecdjzj']
[2022-02-19 00:31:24,777] {standard_task_runner.py:77} INFO - Job 2: Subtask bash_task
[2022-02-19 00:31:24,833] {logging_mixin.py:109} INFO - Running <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [running]> on host 2e85b2b3b082
[2022-02-19 00:31:24,926] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=configuration_dag
AIRFLOW_CTX_TASK_ID=bash_task
AIRFLOW_CTX_EXECUTION_DATE=2020-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-01T00:00:00+00:00
[2022-02-19 00:31:24,927] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 00:31:24,928] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/usr/local/spark/configure.sh ']
[2022-02-19 00:31:24,945] {subprocess.py:85} INFO - Output:
[2022-02-19 00:31:29,597] {subprocess.py:89} INFO - Successfully added `conn_id`=spark_default : spark://:@spark://172.20.0.9:7077:
[2022-02-19 00:31:33,115] {subprocess.py:89} INFO - [[34m2022-02-19 00:31:33,114[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 00:31:33,122] {subprocess.py:89} INFO - Successfully added `conn_id`=minio_default : s3://minio:******@:
[2022-02-19 00:31:37,158] {subprocess.py:89} INFO - [[34m2022-02-19 00:31:37,158[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 00:31:37,166] {subprocess.py:89} INFO - Successfully added `conn_id`=cassandra_default : cassandra://cassandra:******@172.20.0.11:9042
[2022-02-19 00:31:39,262] {subprocess.py:89} INFO - Installed kernelspec python3 in /home/***/.local/share/jupyter/kernels/python3
[2022-02-19 00:31:39,372] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 00:31:39,398] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=configuration_dag, task_id=bash_task, execution_date=20200101T000000, start_date=20220219T003124, end_date=20220219T003139
[2022-02-19 00:31:39,441] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 00:31:39,468] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-19 00:57:18,369] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 00:57:18,382] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 00:57:18,382] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:57:18,382] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-19 00:57:18,382] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:57:18,395] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): bash_task> on 2020-01-01 00:00:00+00:00
[2022-02-19 00:57:18,399] {standard_task_runner.py:52} INFO - Started process 363 to run task
[2022-02-19 00:57:18,402] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'configuration_dag', 'bash_task', 'scheduled__2020-01-01T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/configuration_dag.py', '--cfg-path', '/tmp/tmpfpt5eq99', '--error-file', '/tmp/tmpjozsv0fr']
[2022-02-19 00:57:18,403] {standard_task_runner.py:77} INFO - Job 2: Subtask bash_task
[2022-02-19 00:57:18,458] {logging_mixin.py:109} INFO - Running <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [running]> on host 4861cc27bfb2
[2022-02-19 00:57:18,511] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=configuration_dag
AIRFLOW_CTX_TASK_ID=bash_task
AIRFLOW_CTX_EXECUTION_DATE=2020-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-01T00:00:00+00:00
[2022-02-19 00:57:18,512] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 00:57:18,513] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/usr/local/spark/configure.sh ']
[2022-02-19 00:57:18,523] {subprocess.py:85} INFO - Output:
[2022-02-19 00:57:21,614] {subprocess.py:89} INFO - Successfully added `conn_id`=spark_default : spark://:@spark://172.20.0.9:7077:
[2022-02-19 00:57:25,094] {subprocess.py:89} INFO - [[34m2022-02-19 00:57:25,094[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 00:57:25,110] {subprocess.py:89} INFO - Successfully added `conn_id`=minio_default : s3://minio:******@:
[2022-02-19 00:57:28,979] {subprocess.py:89} INFO - [[34m2022-02-19 00:57:28,979[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 00:57:28,989] {subprocess.py:89} INFO - Successfully added `conn_id`=cassandra_default : cassandra://cassandra:******@172.20.0.11:9042
[2022-02-19 00:57:30,974] {subprocess.py:89} INFO - Installed kernelspec python3 in /home/***/.local/share/jupyter/kernels/python3
[2022-02-19 00:57:31,079] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 00:57:31,109] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=configuration_dag, task_id=bash_task, execution_date=20200101T000000, start_date=20220219T005718, end_date=20220219T005731
[2022-02-19 00:57:31,145] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 00:57:31,174] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-19 01:36:10,515] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 01:36:10,538] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-19 01:36:10,539] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 01:36:10,539] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-19 01:36:10,539] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 01:36:10,564] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): bash_task> on 2020-01-01 00:00:00+00:00
[2022-02-19 01:36:10,569] {standard_task_runner.py:52} INFO - Started process 686 to run task
[2022-02-19 01:36:10,573] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'configuration_dag', 'bash_task', 'scheduled__2020-01-01T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/configuration_dag.py', '--cfg-path', '/tmp/tmpdi0knyb1', '--error-file', '/tmp/tmpftcgcmve']
[2022-02-19 01:36:10,574] {standard_task_runner.py:77} INFO - Job 2: Subtask bash_task
[2022-02-19 01:36:10,656] {logging_mixin.py:109} INFO - Running <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [running]> on host 0b7e9ef53975
[2022-02-19 01:36:10,736] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=configuration_dag
AIRFLOW_CTX_TASK_ID=bash_task
AIRFLOW_CTX_EXECUTION_DATE=2020-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-01T00:00:00+00:00
[2022-02-19 01:36:10,739] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 01:36:10,740] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/usr/local/spark/configure.sh ']
[2022-02-19 01:36:10,753] {subprocess.py:85} INFO - Output:
[2022-02-19 01:36:13,924] {subprocess.py:89} INFO - Successfully added `conn_id`=spark_default : spark://:@spark://172.20.0.9:7077:
[2022-02-19 01:36:17,083] {subprocess.py:89} INFO - [[34m2022-02-19 01:36:17,083[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 01:36:17,091] {subprocess.py:89} INFO - Successfully added `conn_id`=minio_default : s3://minio:******@:
[2022-02-19 01:36:21,510] {subprocess.py:89} INFO - [[34m2022-02-19 01:36:21,510[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-19 01:36:21,517] {subprocess.py:89} INFO - Successfully added `conn_id`=cassandra_default : cassandra://cassandra:******@172.20.0.11:9042
[2022-02-19 01:36:23,328] {subprocess.py:89} INFO - Installed kernelspec python3 in /home/***/.local/share/jupyter/kernels/python3
[2022-02-19 01:36:23,432] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 01:36:23,456] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=configuration_dag, task_id=bash_task, execution_date=20200101T000000, start_date=20220219T013610, end_date=20220219T013623
[2022-02-19 01:36:23,495] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 01:36:23,522] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-22 02:19:23,774] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-22 02:19:23,808] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-22 02:19:23,808] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-22 02:19:23,808] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-22 02:19:23,808] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-22 02:19:23,837] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): bash_task> on 2020-01-01 00:00:00+00:00
[2022-02-22 02:19:23,843] {standard_task_runner.py:52} INFO - Started process 648 to run task
[2022-02-22 02:19:23,846] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'configuration_dag', 'bash_task', 'scheduled__2020-01-01T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/configuration_dag.py', '--cfg-path', '/tmp/tmp3n0i4o3r', '--error-file', '/tmp/tmpr2shjrca']
[2022-02-22 02:19:23,847] {standard_task_runner.py:77} INFO - Job 5: Subtask bash_task
[2022-02-22 02:19:23,915] {logging_mixin.py:109} INFO - Running <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [running]> on host c457bd7a09a1
[2022-02-22 02:19:23,985] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=configuration_dag
AIRFLOW_CTX_TASK_ID=bash_task
AIRFLOW_CTX_EXECUTION_DATE=2020-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-01T00:00:00+00:00
[2022-02-22 02:19:23,986] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-22 02:19:23,987] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/usr/local/spark/configure.sh ']
[2022-02-22 02:19:23,998] {subprocess.py:85} INFO - Output:
[2022-02-22 02:19:27,431] {subprocess.py:89} INFO - A connection with `conn_id`=spark_default already exists.
[2022-02-22 02:19:31,105] {subprocess.py:89} INFO - [[34m2022-02-22 02:19:31,102[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-22 02:19:31,113] {subprocess.py:89} INFO - A connection with `conn_id`=minio_default already exists.
[2022-02-22 02:19:34,855] {subprocess.py:89} INFO - [[34m2022-02-22 02:19:34,855[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-22 02:19:34,862] {subprocess.py:89} INFO - Successfully added `conn_id`=cassandra_default : cassandra://cassandra:******@172.20.0.11:9042
[2022-02-22 02:19:34,869] {subprocess.py:89} INFO - Traceback (most recent call last):
[2022-02-22 02:19:34,869] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO -     cursor, statement, parameters, context
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO -     cursor.execute(statement, parameters)
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "unique_conn_id"
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - DETAIL:  Key (conn_id)=(cassandra_default) already exists.
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - 
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - 
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - The above exception was the direct cause of the following exception:
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - 
[2022-02-22 02:19:34,870] {subprocess.py:89} INFO - Traceback (most recent call last):
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/home/***/.local/bin/***", line 8, in <module>
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -     sys.exit(main())
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/***/__main__.py", line 48, in main
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -     args.func(args)
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/***/cli/cli_parser.py", line 48, in command
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -     return func(*args, **kwargs)
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/***/utils/cli.py", line 92, in wrapper
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -     return f(*args, **kwargs)
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/***/cli/commands/connection_command.py", line 221, in connections_add
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -     raise SystemExit(msg)
[2022-02-22 02:19:34,871] {subprocess.py:89} INFO -   File "/usr/local/lib/python3.7/contextlib.py", line 119, in __exit__
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     next(self.gen)
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/***/utils/session.py", line 32, in create_session
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     session.commit()
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1046, in commit
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     self.transaction.commit()
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 504, in commit
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     self._prepare_impl()
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     self.session.flush()
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
[2022-02-22 02:19:34,872] {subprocess.py:89} INFO -     self._flush(objects)
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -     transaction.rollback(_capture_exception=True)
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -     with_traceback=exc_tb,
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -     raise exception
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -     flush_context.execute()
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -     rec.execute(self)
[2022-02-22 02:19:34,873] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     uow,
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     insert,
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     statement, params
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     return meth(self, multiparams, params)
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     return connection._execute_clauseelement(self, multiparams, params)
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
[2022-02-22 02:19:34,874] {subprocess.py:89} INFO -     distilled_params,
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -     e, statement, parameters, cursor, context
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -     sqlalchemy_exception, with_traceback=exc_info[2], from_=e
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -     raise exception
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -     cursor, statement, parameters, context
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -   File "/home/***/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO -     cursor.execute(statement, parameters)
[2022-02-22 02:19:34,875] {subprocess.py:89} INFO - sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "unique_conn_id"
[2022-02-22 02:19:34,876] {subprocess.py:89} INFO - DETAIL:  Key (conn_id)=(cassandra_default) already exists.
[2022-02-22 02:19:34,876] {subprocess.py:89} INFO - 
[2022-02-22 02:19:34,876] {subprocess.py:89} INFO - [SQL: INSERT INTO connection (conn_id, conn_type, description, host, schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (%(conn_id)s, %(conn_type)s, %(description)s, %(host)s, %(schema)s, %(login)s, %(password)s, %(port)s, %(is_encrypted)s, %(is_extra_encrypted)s, %(extra)s) RETURNING connection.id]
[2022-02-22 02:19:34,876] {subprocess.py:89} INFO - [parameters: {'conn_id': 'cassandra_default', 'conn_type': 'cassandra', 'description': None, 'host': '172.20.0.11', 'schema': None, 'login': 'cassandra', 'password': 'cassandra', 'port': '9042', 'is_encrypted': False, 'is_extra_encrypted': False, 'extra': None}]
[2022-02-22 02:19:34,876] {subprocess.py:89} INFO - (Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-02-22 02:19:36,773] {subprocess.py:89} INFO - Installed kernelspec python3 in /home/***/.local/share/jupyter/kernels/python3
[2022-02-22 02:19:36,884] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-22 02:19:36,912] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=configuration_dag, task_id=bash_task, execution_date=20200101T000000, start_date=20220222T021923, end_date=20220222T021936
[2022-02-22 02:19:36,953] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-22 02:19:36,984] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-22 02:30:14,198] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-22 02:30:14,216] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [queued]>
[2022-02-22 02:30:14,216] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-22 02:30:14,216] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-02-22 02:30:14,216] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-22 02:30:14,230] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): bash_task> on 2020-01-01 00:00:00+00:00
[2022-02-22 02:30:14,235] {standard_task_runner.py:52} INFO - Started process 171 to run task
[2022-02-22 02:30:14,239] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'configuration_dag', 'bash_task', 'scheduled__2020-01-01T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/configuration_dag.py', '--cfg-path', '/tmp/tmpukg166y0', '--error-file', '/tmp/tmp0zd3m9k3']
[2022-02-22 02:30:14,240] {standard_task_runner.py:77} INFO - Job 2: Subtask bash_task
[2022-02-22 02:30:14,308] {logging_mixin.py:109} INFO - Running <TaskInstance: configuration_dag.bash_task scheduled__2020-01-01T00:00:00+00:00 [running]> on host 6670658e93da
[2022-02-22 02:30:14,369] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=configuration_dag
AIRFLOW_CTX_TASK_ID=bash_task
AIRFLOW_CTX_EXECUTION_DATE=2020-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-01T00:00:00+00:00
[2022-02-22 02:30:14,370] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-22 02:30:14,371] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/usr/local/spark/configure.sh ']
[2022-02-22 02:30:14,385] {subprocess.py:85} INFO - Output:
[2022-02-22 02:30:19,410] {subprocess.py:89} INFO - Successfully added `conn_id`=spark_default : spark://:@spark://172.20.0.9:7077:
[2022-02-22 02:30:22,803] {subprocess.py:89} INFO - [[34m2022-02-22 02:30:22,803[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-22 02:30:22,813] {subprocess.py:89} INFO - Successfully added `conn_id`=minio_default : s3://minio:******@:
[2022-02-22 02:30:26,835] {subprocess.py:89} INFO - [[34m2022-02-22 02:30:26,835[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2022-02-22 02:30:26,851] {subprocess.py:89} INFO - Successfully added `conn_id`=cassandra_default : cassandra://cassandra:******@172.20.0.11:9042
[2022-02-22 02:30:28,958] {subprocess.py:89} INFO - Installed kernelspec python3 in /home/***/.local/share/jupyter/kernels/python3
[2022-02-22 02:30:29,067] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-22 02:30:29,093] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=configuration_dag, task_id=bash_task, execution_date=20200101T000000, start_date=20220222T023014, end_date=20220222T023029
[2022-02-22 02:30:29,125] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-22 02:30:29,162] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
